{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import  numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import  Dataset, DataLoader\n",
    "from  PIL import  Image\n",
    "from  torchvision.transforms import  ToTensor, Compose, Resize, CenterCrop\n",
    "import  glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "labels = ['black', 'blue' , 'cyan' , 'gray' , 'green' , 'red' , 'white' , 'yellow']\n",
    "def decode_label(index):\n",
    "    return  labels[index]\n",
    "\n",
    "def encode_label_from_path(path):\n",
    "    for index,value in enumerate(labels):\n",
    "        if value in path:\n",
    "            return  index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "path = '/home/jeetu/Project/VehicleColor/Dataset/'\n",
    "image_list = glob.glob(path + '**/*')\n",
    "class_list = [encode_label_from_path(item) for item in image_list]\n",
    "x_train, x_test , y_train , y_test = train_test_split(image_list, class_list, train_size= 0.5 , stratify=class_list , shuffle=True, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class VehicleColorDataset(Dataset):\n",
    "    def __init__(self, image_list, class_list, transforms = None):\n",
    "        self.transform = transforms\n",
    "        self.image_list = image_list\n",
    "        self.class_list = class_list\n",
    "        self.data_len = len(self.image_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_list[index]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.class_list[index]\n",
    "\n",
    "transforms=Compose([Resize(224),  CenterCrop(224) , ToTensor()])\n",
    "train_dataset = VehicleColorDataset( x_train , y_train , transforms)\n",
    "train_data_loader = DataLoader(train_dataset,batch_size=115 )\n",
    "test_dataset = VehicleColorDataset(x_test, y_test,transforms)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=115)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#Define Model\n",
    "class VehicleColorModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VehicleColorModel, self).__init__()\n",
    "\n",
    "        self.top_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3,48, kernel_size=(11,11) , stride=(4,4)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(48),\n",
    "            nn.MaxPool2d(kernel_size=3 , stride=2)\n",
    "        )\n",
    "\n",
    "        # first top convolution layer    after split\n",
    "        self.top_top_conv2 = nn.Sequential(\n",
    "\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(24, 64, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.top_bot_conv2 = nn.Sequential(\n",
    "\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(24, 64, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "\n",
    "        #  need a concat\n",
    "\n",
    "        # after concat\n",
    "        self.top_conv3 = nn.Sequential(\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(128, 192, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # fourth top convolution layer\n",
    "        # split feature map by half\n",
    "        self.top_top_conv4 = nn.Sequential(\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(96, 96, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.top_bot_conv4 = nn.Sequential(\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(96, 96, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "        # fifth top convolution layer\n",
    "        self.top_top_conv5 = nn.Sequential(\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(96, 64, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.top_bot_conv5 = nn.Sequential(\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(96, 64, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "#        # ===============================  bottom ================================\n",
    "\n",
    "\n",
    "#         # first bottom convolution layer\n",
    "        self.bottom_conv1 = nn.Sequential(\n",
    "\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(3, 48, kernel_size=(11,11), stride=(4,4)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(48),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "\n",
    "        # first top convolution layer    after split\n",
    "        self.bottom_top_conv2 = nn.Sequential(\n",
    "\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(24, 64, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.bottom_bot_conv2 = nn.Sequential(\n",
    "\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(24, 64, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "\n",
    "        #  need a concat\n",
    "\n",
    "        # after concat\n",
    "        self.bottom_conv3 = nn.Sequential(\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(128, 192, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # fourth top convolution layer\n",
    "        # split feature map by half\n",
    "        self.bottom_top_conv4 = nn.Sequential(\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(96, 96, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.bottom_bot_conv4 = nn.Sequential(\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(96, 96, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "        # fifth top convolution layer\n",
    "        self.bottom_top_conv5 = nn.Sequential(\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(96, 64, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.bottom_bot_conv5 = nn.Sequential(\n",
    "            # 1-1 conv layer\n",
    "            nn.Conv2d(96, 64, kernel_size=(3,3), stride=(1,1),padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        # Fully-connected layer\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(5*5*64*4, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.7),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.6),\n",
    "            nn.Linear(4096, 8)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        # print(x.shape)\n",
    "        x_top = self.top_conv1(x)\n",
    "        # print(x_top.shape)\n",
    "\n",
    "        x_top_conv = torch.split(x_top, 24, 1)\n",
    "\n",
    "        x_top_top_conv2 = self.top_top_conv2(x_top_conv[0])\n",
    "        x_top_bot_conv2 = self.top_bot_conv2(x_top_conv[1])\n",
    "\n",
    "        x_top_cat1 = torch.cat([x_top_top_conv2,x_top_bot_conv2],1)\n",
    "\n",
    "        x_top_conv3 = self.top_conv3(x_top_cat1)\n",
    "\n",
    "        x_top_conv3 = torch.split(x_top_conv3, 96, 1)\n",
    "\n",
    "        x_top_top_conv4 = self.top_top_conv4(x_top_conv3[0])\n",
    "        x_top_bot_conv4 = self.top_bot_conv4(x_top_conv3[1])\n",
    "\n",
    "        x_top_top_conv5 = self.top_top_conv5(x_top_top_conv4)\n",
    "        x_top_bot_conv5 = self.top_bot_conv5(x_top_bot_conv4)\n",
    "\n",
    "        x_bottom = self.bottom_conv1(x)\n",
    "\n",
    "        x_bottom_conv = torch.split(x_bottom, 24, 1)\n",
    "\n",
    "        x_bottom_top_conv2 = self.bottom_top_conv2(x_bottom_conv[0])\n",
    "        x_bottom_bot_conv2 = self.bottom_bot_conv2(x_bottom_conv[1])\n",
    "\n",
    "        x_bottom_cat1 = torch.cat([x_bottom_top_conv2,x_bottom_bot_conv2],1)\n",
    "\n",
    "        x_bottom_conv3 = self.bottom_conv3(x_bottom_cat1)\n",
    "\n",
    "        x_bottom_conv3 = torch.split(x_bottom_conv3, 96, 1)\n",
    "\n",
    "        x_bottom_top_conv4 = self.bottom_top_conv4(x_bottom_conv3[0])\n",
    "        x_bottom_bot_conv4 = self.bottom_bot_conv4(x_bottom_conv3[1])\n",
    "\n",
    "        x_bottom_top_conv5 = self.bottom_top_conv5(x_bottom_top_conv4)\n",
    "        x_bottom_bot_conv5 = self.bottom_bot_conv5(x_bottom_bot_conv4)\n",
    "\n",
    "        x_cat = torch.cat([x_top_top_conv5,x_top_bot_conv5,x_bottom_top_conv5,x_bottom_bot_conv5],1)\n",
    "\n",
    "\n",
    "        flatten = x_cat.view(x_cat.size(0), -1)\n",
    "\n",
    "        output = self.classifier(flatten)\n",
    "\n",
    "        #output = F.softmax(output)\n",
    "\n",
    "\n",
    "        return output\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# Save Model\n",
    "Model_Path = '/home/jeetu/Project/VehicleColorA'\n",
    "logger = Logger(Model_Path, \"Exp1\", 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = VehicleColorModel()\n",
    "model.cuda()\n",
    "opt = torch.optim.SGD(model.parameters(), momentum=0.9, lr = 0.001 )\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, patience=20,min_lr=1e-08,factor=0.1,verbose=True)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train | Epoch 0: 100%|██████████| 68/68 [01:11<00:00,  1.05batch/s, loss=0.384]\n",
      "Test | Epoch 0: 100%|██████████| 68/68 [00:59<00:00,  1.17batch/s, accuracy=84.7, loss=0.413]\n",
      "Train | Epoch 1: 100%|██████████| 68/68 [01:11<00:00,  1.05batch/s, loss=0.368]\n",
      "Test | Epoch 1: 100%|██████████| 68/68 [00:59<00:00,  1.22batch/s, accuracy=85.6, loss=0.396]\n",
      "Train | Epoch 2: 100%|██████████| 68/68 [01:11<00:00,  1.01s/batch, loss=0.355]\n",
      "Test | Epoch 2: 100%|██████████| 68/68 [00:59<00:00,  1.20batch/s, accuracy=85.2, loss=0.398]\n",
      "Train | Epoch 3:  44%|████▍     | 30/68 [00:33<00:42,  1.12s/batch, loss=0.358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model...\n",
      "Saving Model...\n",
      "Saving Model...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-44-25d991d8008e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m         \u001B[0mrunning_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m         \u001B[0mbatch_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m         \u001B[0;32mfor\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0my\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtepoch\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m             \u001B[0mtepoch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_description\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Train | Epoch {epoch}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m             \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'cuda'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tqdm/_tqdm.py\u001B[0m in \u001B[0;36m__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1020\u001B[0m                 \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001B[1;32m   1021\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1022\u001B[0;31m             \u001B[0;32mfor\u001B[0m \u001B[0mobj\u001B[0m \u001B[0;32min\u001B[0m \u001B[0miterable\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1023\u001B[0m                 \u001B[0;32myield\u001B[0m \u001B[0mobj\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1024\u001B[0m                 \u001B[0;31m# Update and possibly print the progressbar.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    343\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    344\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__next__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 345\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    346\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    347\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[0;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    383\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    384\u001B[0m         \u001B[0mindex\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 385\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_fetcher\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    386\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    387\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001B[0m in \u001B[0;36mfetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 44\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     45\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 44\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     45\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-11-b2b0c894ccfc>\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, index)\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__getitem__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m         \u001B[0mimage_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimage_list\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m         \u001B[0mimage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mImage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvert\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'RGB'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m             \u001B[0mimage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/PIL/Image.py\u001B[0m in \u001B[0;36mconvert\u001B[0;34m(self, mode, matrix, dither, palette, colors)\u001B[0m\n\u001B[1;32m    932\u001B[0m         \"\"\"\n\u001B[1;32m    933\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 934\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    935\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    936\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mmode\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"P\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/PIL/ImageFile.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    251\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    252\u001B[0m                             \u001B[0mb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mb\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0ms\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 253\u001B[0;31m                             \u001B[0mn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merr_code\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdecoder\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    254\u001B[0m                             \u001B[0;32mif\u001B[0m \u001B[0mn\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    255\u001B[0m                                 \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "from  tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "for epoch in range(epochs):\n",
    "    with tqdm(train_data_loader, unit=\"batch\") as tepoch:\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        batch_ = 0\n",
    "        for X,y in tepoch:\n",
    "            tepoch.set_description(f\"Train | Epoch {epoch}\")\n",
    "            X = X.to('cuda')\n",
    "            y = y.to('cuda')\n",
    "            pred = model.forward(X)\n",
    "            loss_value = loss_fn(pred, y)\n",
    "            loss_value.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            batch_ +=1\n",
    "            running_loss += loss_value.item()\n",
    "            tepoch.set_postfix(loss = running_loss/batch_)\n",
    "        logger.log('train_loss', running_loss/batch_)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        with tqdm(test_data_loader, unit=\"batch\") as tepoch:\n",
    "            tepoch.set_description(f\"Test | Epoch {epoch}\")\n",
    "            correct = 0\n",
    "            n_batch = 0\n",
    "            running_loss = 0\n",
    "            for X,y in tepoch:\n",
    "                X, y = X.to('cuda') , y.to('cuda')\n",
    "                pred = model.forward(X)\n",
    "                pred_class = pred.argmax(dim = 1)\n",
    "                loss_value = loss_fn(pred,y)\n",
    "                running_loss += loss_value.item()\n",
    "                curr_correct = (pred_class == y).float().sum().item()\n",
    "                correct += curr_correct\n",
    "                n_batch +=1\n",
    "                tepoch.set_postfix(loss = running_loss/n_batch , accuracy = correct / (n_batch*115) *100)\n",
    "            logger.log('test_loss', running_loss/n_batch)\n",
    "            logger.log('test_acc', correct/(n_batch*115))\n",
    "    logger.checkpoint(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "from  collections import  defaultdict\n",
    "import json\n",
    "class Logger(object):\n",
    "    def __init__(self, log_dir, name, chkpt_interval):\n",
    "        super(Logger,self).__init__()\n",
    "        self.chkpt_interval = chkpt_interval\n",
    "        self.log_dir = log_dir\n",
    "        self.name = name\n",
    "        os.makedirs(os.path.join(log_dir, name), exist_ok= True)\n",
    "        self.log_path = os.path.join(log_dir, name, 'logs.json')\n",
    "        self.model_path = os.path.join(log_dir, name, 'model.pt')\n",
    "        self.logs = defaultdict(list)\n",
    "        self.logs['epoch'] = 0\n",
    "\n",
    "    def log(self, key, value ):\n",
    "        if isinstance(value, dict):\n",
    "            for k,v in value.items():\n",
    "                self.log(f'{key}.{k}',v)\n",
    "        else:\n",
    "            self.logs[key].append(value)\n",
    "\n",
    "    def checkpoint(self, model):\n",
    "        if (self.logs['epoch'] + 1 ) % self.chkpt_interval == 0:\n",
    "            self.save(model)\n",
    "        self.logs['epoch'] +=1\n",
    "\n",
    "    def save(self, model):\n",
    "        print(\"Saving Model...\")\n",
    "        with open(self.log_path, 'w') as f:\n",
    "            json.dump(self.logs, f, sort_keys=True, indent=4)\n",
    "        epch = self.logs['epoch'] + 1\n",
    "        torch.save(model.state_dict(), os.path.join(self.log_dir, self.name, f'model_{epch}.pt'))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-72b5a700",
   "language": "python",
   "display_name": "PyCharm (pythonProject)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}